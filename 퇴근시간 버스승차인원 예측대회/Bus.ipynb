{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bus.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYh2ABrTWlxh",
        "colab_type": "text"
      },
      "source": [
        "# 라이브러리 및 데이터"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92vIji09WeHa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# base\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import numpy as np\n",
        "import time\n",
        "from collections import Counter\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# data preprocessing\n",
        "import pandas as pd\n",
        "pd.set_option('max_columns', 130, 'max_rows', 30)\n",
        "\n",
        "# visualization\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.rc('font', family='Malgun Gothic')\n",
        "plt.rc('axes', unicode_minus=False)\n",
        "\n",
        "# ignore warining\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "import folium # 지도 관련 시각화\n",
        "from folium.plugins import MarkerCluster #지도 관련 시각화\n",
        "import geopy.distance #거리 계산해주는 패키지 사용\n",
        "\n",
        "\n",
        "# save\n",
        "from sklearn.externals import joblib \n",
        "import pickle\n",
        "\n",
        "# selenium\n",
        "from selenium.webdriver import Chrome\n",
        "\n",
        "import geopy.distance\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.externals import joblib \n",
        "import pickle\n",
        "\n",
        "import random\n",
        "random.seed(42)\n",
        "\n",
        "import lightgbm as lgb\n",
        "from keras import metrics\n",
        "from sklearn.metrics import r2_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGn2AFhDW0tp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv(\"train.csv\")\n",
        "test = pd.read_csv(\"test.csv\")\n",
        "bts = pd.read_csv(\"bus_bts.csv\")\n",
        "\n",
        "train.shape, test.shape, bts.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DBe552RW6rq",
        "colab_type": "text"
      },
      "source": [
        "CRAWLING CODE\n",
        "기상청 날씨누리 사이트에서 지상 관측 자료를 크롤링 함\n",
        "http://www.weather.go.kr/\n",
        "중급자 코드가 올라오기 전에 수행 함\n",
        "중급자 코드에서 weather.csv를 만드는 코드가 있는데 제주감귤팀이 제출한 weather.csv는 이 크롤링을 통해 만들어진 것이고, 중급자 코드에 해당하는 weather.csv가 아님\n",
        "chromedriver.exe를 작업 경로에 위치시켜야 함\n",
        "2019년 9월 1일부터 2019년 10월 16일 까지의 데이터를 크롤링하였으며, 오전 10시의 관측 데이터만 사용하였기 때문에 data leakage에 해당하지 않는다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZytIO6oW0wr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def crawl_weather() :\n",
        "    \n",
        "    weather_data_10 = pd.DataFrame(columns=['현재일기_10','현재기온_10','체감온도_10','일강수_10'])\n",
        "    browser = Chrome()\n",
        "    url = 'http://www.weather.go.kr/weather/observation/currentweather.jsp?auto_man=m&type=t99&reg=184&tm=2019.10.25.16%3A00&x=19&y=7'\n",
        "    browser.get(url)\n",
        "\n",
        "    for i in range(0,46):\n",
        "        i+=1\n",
        "\n",
        "        elem=browser.find_element_by_id('observation_text')\n",
        "        elem.clear()\n",
        "        elem.send_keys(\"2019.9.{}.10:00\".format(i))\n",
        "\n",
        "        btn=browser.find_elements_by_class_name('btn')\n",
        "        btn[2].click()\n",
        "        \n",
        "        time.sleep(1)\n",
        "        weathers = browser.find_elements_by_css_selector('td')\n",
        "        weather_data_10 = weather_data_10.append(pd.DataFrame([[weathers[40].text,weathers[44].text, weathers[46].text, weathers[47].text]],columns=['현재일기_10','현재기온_10','체감온도_10','일강수_10']))\n",
        "        \n",
        "            \n",
        "    print('success !')\n",
        "    browser.close()\n",
        "    \n",
        "    return weather_data_10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R1ZKZQSYW0zg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weather_data = crawl_weather()\n",
        "weather_data.to_csv('weather.csv', index = False)\n",
        "\n",
        "print('save.. !')\n",
        "weather_data = pd.read_csv('weather.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Id5xKNNXMkk",
        "colab_type": "text"
      },
      "source": [
        "# 데이터 전처리\n",
        "#탐색적 자료분석\n",
        "#변수 선택 및 모델 구축\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lGl_4dhW02g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# weekday\n",
        "train['date'] = pd.to_datetime(train['date'])\n",
        "train['weekday'] = train['date'].dt.weekday\n",
        "\n",
        "test['date'] = pd.to_datetime(test['date'])\n",
        "test['weekday'] = test['date'].dt.weekday\n",
        "\n",
        "train.shape, test.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_49EJB7W05O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# route_station = bus_route_id + station_code\n",
        "train['bus_route_id'] = train['bus_route_id'].astype(str)\n",
        "train['station_code'] = train['station_code'].astype(str)\n",
        "train['route_station'] = train['bus_route_id'] + ',' + train['station_code']\n",
        "\n",
        "test['bus_route_id'] = test['bus_route_id'].astype(str)\n",
        "test['station_code'] = test['station_code'].astype(str)\n",
        "test['route_station'] = test['bus_route_id'] + ',' + test['station_code']\n",
        "\n",
        "train.shape, test.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgZDiITvW08G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# bus_route_id_weekday = bus_route_id + weekday\n",
        "train['bus_route_id_weekday'] = train['bus_route_id'].astype(str) + ',' + train['weekday'].astype(str) \n",
        "test['bus_route_id_weekday'] = test['bus_route_id'].astype(str) + ',' + test['weekday'].astype(str) \n",
        "\n",
        "train.shape, test.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNJiv189W0_O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# station_code_weekday = station_code + weekday\n",
        "train['station_code_weekday'] = train['station_code'].astype(str) + ',' + train['weekday'].astype(str)\n",
        "test['station_code_weekday'] = test['station_code'].astype(str) + ',' + test['weekday'].astype(str)\n",
        "\n",
        "train.shape, test.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEd9rLEBW1CO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# route_station_weekday = route_station + weekay\n",
        "train['route_station_weekday'] = train['route_station'].astype(str) + ',' + train['weekday'].astype(str) \n",
        "test['route_station_weekday'] = test['route_station'].astype(str) + ',' + test['weekday'].astype(str)\n",
        "\n",
        "train.shape, test.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGo2TPM8W1FI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# on_time - bts.csv 데이터에서 geton_time 열에서 시간대만 추출하여 on_time 컬럼을 만듬\n",
        "bts['on_time']  = bts['geton_time'].apply(lambda x : x[:2])\n",
        "\n",
        "bts.iloc[bts.query('on_time == \"06\"').index,13] = '6~7_ride'\n",
        "bts.iloc[bts.query('on_time == \"07\"').index,13] = '7~8_ride'\n",
        "bts.iloc[bts.query('on_time == \"08\"').index,13] = '8~9_ride'\n",
        "bts.iloc[bts.query('on_time == \"09\"').index,13] = '9~10_ride'\n",
        "bts.iloc[bts.query('on_time == \"10\"').index,13] = '10~11_ride'\n",
        "bts.iloc[bts.query('on_time == \"11\"').index,13] = '11~12_ride'\n",
        "\n",
        "bts.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFB8dUH1W1ID",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 승 하차 시간대 통합 변수 (t ~ t+2)\n",
        "# t~t+1, t+1~t+2 시간대 승하차인원을 합하여 t~t+2 시간대 승하차인원 변수를 만듬\n",
        "train['68a']=train['6~7_ride']+train['7~8_ride'] \n",
        "train['810a']=train['8~9_ride']+train['9~10_ride']\n",
        "train['1012a']=train['10~11_ride']+train['11~12_ride']\n",
        "\n",
        "train['68b']=train['6~7_takeoff']+train['7~8_takeoff'] \n",
        "train['810b']=train['8~9_takeoff']+train['9~10_takeoff']\n",
        "train['1012b']=train['10~11_takeoff']+train['11~12_takeoff']\n",
        "\n",
        "test['68a']=test['6~7_ride']+test['7~8_ride']\n",
        "test['810a']=test['8~9_ride']+test['9~10_ride']\n",
        "test['1012a']=test['10~11_ride']+test['11~12_ride']\n",
        "\n",
        "test['68b']=test['6~7_takeoff']+test['7~8_takeoff']\n",
        "test['810b']=test['8~9_takeoff']+test['9~10_takeoff']\n",
        "test['1012b']=test['10~11_takeoff']+test['11~12_takeoff']\n",
        "\n",
        "train.shape, test.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSww7-xkW1LI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make features by using target variable\n",
        "# 우리가 최종적으로 예측해야할 것은 각 일자별(date), 버스 노선(bus_route_id) 상의 정류장(station_name)의 퇴근시간 하차인원(18~20_ride)이다.\n",
        "\n",
        "# bus_route_id, station_name, weekday의 각 조합별 퇴근시간 하차인원(18~20_ride)의 여러 통계량을 구한 후 이를 train set, test set에 모두 적용한다.\"\n",
        "# target 변수를 train, test set에 적용할 수 있는 이유는 우리가 예측해야할 id는 date, bus_rout_id, station_name으로 구성되어있기 때문이다. 즉, 각각의 노선, 정류장별로 공통적인 패턴이 존재할 수 있다.\n",
        "# 이 과정에서 NA 값이 생기는 이유는 train set에 없는 bus_route_id, station_name이 존재하기 때문이다.\n",
        "def id_statistic(ID, col1, col2) :\n",
        "    \n",
        "    # mean, sum\n",
        "    rs_mean = train.groupby([ID])['18~20_ride'].agg([(col1, 'mean')]).reset_index()\n",
        "    rs_sum = train.groupby([ID])['18~20_ride'].agg([(col2, 'sum')]).reset_index()\n",
        "    rs_mean_sum = pd.merge(rs_mean, rs_sum, on=ID)\n",
        "\n",
        "    # merge\n",
        "    tr = pd.merge(train, rs_mean_sum, how='left', on=ID)\n",
        "    te = pd.merge(test, rs_mean_sum, how='left', on=ID)\n",
        "\n",
        "    # na -&gt; mean\n",
        "    te[col1] = te[col1].fillna(rs_mean.mean())\n",
        "    te[col1] = te[col1].fillna(rs_sum.mean())\n",
        "    \n",
        "    return tr, te"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0BgpTBbW1OE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, test = id_statistic('route_station', '1820_rs_mean', '1820_rs_sum')\n",
        "\n",
        "train.shape, test.shape\n",
        "\n",
        "train, test = id_statistic('bus_route_id', '1820_r_mean', '1820_r_sum')\n",
        "\n",
        "train.shape, test.shape\n",
        "\n",
        "train, test = id_statistic('station_code', '1820_s_mean', '1820_s_sum')\n",
        "\n",
        "train.shape, test.shape\n",
        "\n",
        "train, test = id_statistic('weekday', '1820_w_mean', '1820_w_sum')\n",
        "\n",
        "train.shape, test.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50gl62qIW1Qp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def mean_statistics() :\n",
        "\n",
        "    f = train.groupby(['bus_route_id_weekday'])['18~20_ride'].agg([('mean_bus_weekday_ride','mean')]).reset_index()\n",
        "    tr = pd.merge(train, f, how='left', on='bus_route_id_weekday')\n",
        "    te = pd.merge(test, f, how='left', on='bus_route_id_weekday').fillna(f['mean_bus_weekday_ride'].mean())\n",
        "    \n",
        "    f = train.groupby(['station_code_weekday'])['18~20_ride'].agg([('mean_station_weekday_ride','mean')]).reset_index()\n",
        "    tr = pd.merge(tr, f, how='left', on='station_code_weekday')\n",
        "    te = pd.merge(te, f, how='left', on='station_code_weekday').fillna(f['mean_station_weekday_ride'].mean())\n",
        "    \n",
        "    f = train.groupby(['route_station_weekday'])['18~20_ride'].agg([('mean_route_station_weekday_ride','mean')]).reset_index()\n",
        "    tr = pd.merge(tr, f, how='left', on='route_station_weekday')\n",
        "    te = pd.merge(te, f, how='left', on='route_station_weekday').fillna(f['mean_route_station_weekday_ride'].mean())\n",
        "    \n",
        "    return tr, te"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbFjOlKFYK1m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, test = mean_statistics()\n",
        "\n",
        "train.shape, test.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4XrJy_nYK67",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# congestion - bus_route_id를 기준으로 18 ~ 20의 혼잡도를 계산한다.\n",
        "def congestion() :\n",
        "    df = train.groupby(['bus_route_id'])['18~20_ride'].agg([('passenger', 'sum')])\n",
        "    df = df.sort_values(by='passenger', ascending=False).reset_index()\n",
        "    \n",
        "    def f(x):\n",
        "        if x &gt; 10000:\n",
        "            return 7\n",
        "\n",
        "        elif x &gt; 5000:\n",
        "            return 6\n",
        "\n",
        "        elif x &gt; 2000:\n",
        "            return 5\n",
        "\n",
        "        elif x &gt; 700:\n",
        "            return 4\n",
        "\n",
        "        elif x &gt; 200:\n",
        "            return 3\n",
        "\n",
        "        elif x &gt; 50:\n",
        "            return 2\n",
        "\n",
        "        else:\n",
        "            return 1\n",
        "    \n",
        "    df['congestion']=df['passenger'].apply(f)\n",
        "    df = df[['bus_route_id','congestion']]\n",
        "    \n",
        "    tr = pd.merge(train, df, how='left', on='bus_route_id')\n",
        "    te = pd.merge(test, df, how='left', on='bus_route_id')\n",
        "    \n",
        "    # 결측치는 데이터 프레임 df의 'congestion'의 중간값인 '4'으로 대체\n",
        "    te = te.fillna(4)\n",
        "    \n",
        "    return tr, te"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FNq_PHYYK_5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train, test = congestion()\n",
        "\n",
        "train.shape, test.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgB3_7SDYLFw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# location = latitude + longitude\n",
        "train['location'] = train['latitude'].astype(str) + ',' + train['longitude'].astype(str)\n",
        "test['location'] = test['latitude'].astype(str) + ',' + test['longitude'].astype(str)\n",
        "\n",
        "train.shape, test.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vqgk-ktyYLLx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# merge key\n",
        "# make cue column\n",
        "train['cue']=0\n",
        "test['cue']=1\n",
        "\n",
        "train.shape, test.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zemidJfYLQe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 오전 시간의 여러 데이터 활용한 변수\n",
        "# 오전 시간의 탑승 및 하차 데이터를 활용하여 요약통계량을 만든다.\n",
        "def morning() :\n",
        "    \n",
        "    # merge\n",
        "    data = pd.concat([train, test])\n",
        "    \n",
        "    a = data.groupby(['route_station'])['1012a'].agg({'sum', 'mean'}).reset_index()\n",
        "    a.columns = ['route_station', '1012a_sum','1012a_mean']\n",
        "\n",
        "    b = data.groupby(['route_station'])['1012b'].agg({'sum', 'mean'}).reset_index()\n",
        "    b.columns = ['route_station', '1012b_sum','1012b_mean']\n",
        "    b = b[['1012b_sum','1012b_mean']]\n",
        "\n",
        "    c = data.groupby(['route_station'])['10~11_ride'].agg({'sum', 'mean'}).reset_index()\n",
        "    c.columns = ['route_station', '10~11_ride_sum','10~11_ride_mean']\n",
        "    c = c[['10~11_ride_sum','10~11_ride_mean']]\n",
        "\n",
        "    d = data.groupby(['route_station'])['10~11_takeoff'].agg({'sum', 'mean'}).reset_index()\n",
        "    d.columns = ['route_station', '10~11_takeoff_sum','10~11_takeoff_mean']\n",
        "    d = d[['10~11_takeoff_sum','10~11_takeoff_mean']]\n",
        "\n",
        "    e = data.groupby(['route_station'])['11~12_ride'].agg({'sum', 'mean'}).reset_index()\n",
        "    e.columns = ['route_station', '11~12_ride_sum','11~12_ride_mean']\n",
        "    e = e[['11~12_ride_sum','11~12_ride_mean']]\n",
        "\n",
        "    f = data.groupby(['route_station'])['11~12_takeoff'].agg({'sum', 'mean'}).reset_index()\n",
        "    f.columns = ['route_station', '11~12_takeoff_sum','11~12_takeoff_mean']\n",
        "    f = f[['11~12_takeoff_sum','11~12_takeoff_mean']]\n",
        "\n",
        "    g = data.groupby(['route_station'])['1820_r_mean'].agg({'sum', 'mean'}).reset_index()\n",
        "    g.columns = ['route_station', '1820_r_mean_sum','1820_r_mean_mean']\n",
        "    g = g[['1820_r_mean_sum','1820_r_mean_mean']]\n",
        "\n",
        "    h = data.groupby(['route_station'])['1820_r_sum'].agg({'sum', 'mean'}).reset_index()\n",
        "    h.columns = ['route_station', '1820_r_sum_sum','1820_r_sum_mean']\n",
        "    h = h[['1820_r_sum_sum','1820_r_sum_mean']]\n",
        "\n",
        "    i = data.groupby(['route_station'])['1820_rs_mean'].agg({'sum', 'mean'}).reset_index()\n",
        "    i.columns = ['route_station', '1820_rs_mean_sum','1820_rs_mean_mean']\n",
        "    i = i[['1820_rs_mean_sum','1820_rs_mean_mean']]\n",
        "\n",
        "    j = data.groupby(['route_station'])['1820_rs_sum'].agg({'sum', 'mean'}).reset_index()\n",
        "    j.columns = ['route_station', '1820_rs_sum_sum','1820_rs_sum_mean']\n",
        "    j = j[['1820_rs_sum_sum','1820_rs_sum_mean']]\n",
        "\n",
        "    k = data.groupby(['route_station'])['1820_s_mean'].agg({'sum', 'mean'}).reset_index()\n",
        "    k.columns = ['route_station', '1820_s_mean_sum','1820_s_mean_mean']\n",
        "    k = k[['1820_s_mean_sum','1820_s_mean_mean']]\n",
        "\n",
        "    l = data.groupby(['route_station'])['1820_s_sum'].agg({'sum', 'mean'}).reset_index()\n",
        "    l.columns = ['route_station', '1820_s_sum_sum','1820_s_sum_mean']\n",
        "    l = l[['1820_s_sum_sum','1820_s_sum_mean']]\n",
        "\n",
        "    m = data.groupby(['route_station'])['1820_w_mean'].agg({'sum', 'mean'}).reset_index()\n",
        "    m.columns = ['route_station', '1820_w_mean_sum','1820_w_mean_mean']\n",
        "    m = m[['1820_w_mean_sum','1820_w_mean_mean']]\n",
        "\n",
        "    n = data.groupby(['route_station'])['1820_w_sum'].agg({'sum', 'mean'}).reset_index()\n",
        "    n.columns = ['route_station', '1820_w_sum_sum','1820_w_sum_mean']\n",
        "    n = n[['1820_w_sum_sum','1820_w_sum_mean']]\n",
        "\n",
        "    o = data.groupby(['route_station'])['68a'].agg({'sum', 'mean'}).reset_index()\n",
        "    o.columns = ['route_station', '68a_sum','68a_mean']\n",
        "    o = o[['68a_sum','68a_mean']]\n",
        "\n",
        "    p = data.groupby(['route_station'])['68b'].agg({'sum', 'mean'}).reset_index()\n",
        "    p.columns = ['route_station', '68b_sum','68b_mean']\n",
        "    p = p[['68b_sum','68b_mean']]\n",
        "\n",
        "    q = data.groupby(['route_station'])['6~7_ride'].agg({'sum', 'mean'}).reset_index()\n",
        "    q.columns = ['route_station', '6~7_ride_sum','6~7_ride_mean']\n",
        "    q = q[['6~7_ride_sum','6~7_ride_mean']]\n",
        "\n",
        "    r = data.groupby(['route_station'])['6~7_takeoff'].agg({'sum', 'mean'}).reset_index()\n",
        "    r.columns = ['route_station', '6~7_takeoff_sum','6~7_takeoff_mean']\n",
        "    r = r[['6~7_takeoff_sum','6~7_takeoff_mean']]\n",
        "\n",
        "    s = data.groupby(['route_station'])['7~8_ride'].agg({'sum', 'mean'}).reset_index()\n",
        "    s.columns = ['route_station', '7~8_ride_sum','7~8_ride_mean']\n",
        "    s = s[['7~8_ride_sum','7~8_ride_mean']]\n",
        "\n",
        "    t = data.groupby(['route_station'])['7~8_takeoff'].agg({'sum', 'mean'}).reset_index()\n",
        "    t.columns = ['route_station', '7~8_takeoff_sum','7~8_takeoff_mean']\n",
        "    t = t[['7~8_takeoff_sum','7~8_takeoff_mean']]\n",
        "\n",
        "    u = data.groupby(['route_station'])['810a'].agg({'sum', 'mean'}).reset_index()\n",
        "    u.columns = ['route_station', '810a_sum','810a_mean']\n",
        "    u = u[['810a_sum','810a_mean']]\n",
        "\n",
        "    v = data.groupby(['route_station'])['810b'].agg({'sum', 'mean'}).reset_index()\n",
        "    v.columns = ['route_station', '810b_sum','810b_mean']\n",
        "    v = v[['810b_sum','810b_mean']]\n",
        "\n",
        "    w = data.groupby(['route_station'])['8~9_ride'].agg({'sum', 'mean'}).reset_index()\n",
        "    w.columns = ['route_station', '8~9_ride_sum','8~9_ride_mean']\n",
        "    w = w[['8~9_ride_sum','8~9_ride_mean']]\n",
        "\n",
        "    x = data.groupby(['route_station'])['8~9_takeoff'].agg({'sum', 'mean'}).reset_index()\n",
        "    x.columns = ['route_station', '8~9_takeoff_sum','8~9_takeoff_mean']\n",
        "    x = x[['8~9_takeoff_sum','8~9_takeoff_mean']]\n",
        "\n",
        "    y = data.groupby(['route_station'])['9~10_ride'].agg({'sum', 'mean'}).reset_index()\n",
        "    y.columns = ['route_station', '9~10_ride_sum','9~10_ride_mean']\n",
        "    y = y[['9~10_ride_sum','9~10_ride_mean']]\n",
        "\n",
        "    z = data.groupby(['route_station'])['9~10_takeoff'].agg({'sum', 'mean'}).reset_index()\n",
        "    z.columns = ['route_station', '9~10_takeoff_sum','9~10_takeoff_mean']\n",
        "    z = z[['9~10_takeoff_sum','9~10_takeoff_mean']]\n",
        "    \n",
        "    df = pd.concat([a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u,v,w,x,y,z],axis=1)\n",
        "    df = pd.merge(data, df, how='left', on='route_station')\n",
        "    \n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMYpvz5fYLVZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = morning()\n",
        "\n",
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_5R6YMjYLZ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 배차 간격\n",
        "# 배차 간격 변수를 만들 때는 많은 시간이 소요됩니다. 따라서 위의 과정의 결과를 데이터프레임으로 구성해놓았습니다.\n",
        "train['bus_route_id'] = train['bus_route_id'].astype(np.int64)\n",
        "test['bus_route_id'] = test['bus_route_id'].astype(np.int64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noABAzqoYLe8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bts['geton_time2'] = pd.to_datetime(bts['geton_time'])\n",
        "\n",
        "f = bts.groupby(['geton_date','geton_time2','geton_station_code','bus_route_id'])['user_count'].\\\n",
        "agg([('탑승객_수','sum')]).reset_index().\\\n",
        "sort_values(by=['geton_date','geton_station_code','bus_route_id','geton_time2'], ascending=True).reset_index()\n",
        "\n",
        "f['index'] = list(range(0,len(f)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyYHi1GfYLiK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "time = []\n",
        "\n",
        "for i in range(0,len(f)-1):\n",
        "\n",
        "    if ((f.iloc[i].geton_date == f.iloc[i+1].geton_date) &\\\n",
        "        (f.iloc[i].geton_station_code == f.iloc[i+1].geton_station_code) &\\\n",
        "        (f.iloc[i].bus_route_id == f.iloc[i+1].bus_route_id)):\n",
        "\n",
        "        time.append(f.iloc[i+1].geton_time2 - f.iloc[i].geton_time2)\n",
        "\n",
        "    else:\n",
        "        time.append(0)\n",
        "\n",
        "time.insert(0, '0')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JssJfr8VYsQd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_sec(time_str):\n",
        "\n",
        "    h, m, s = time_str.split(':')\n",
        "\n",
        "    return int(h) * 3600 + int(m) * 60 + int(s)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTjwkZccYsVL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def bus_interval() :\n",
        "\n",
        "    f['time'] = time\n",
        "    f['time2'] = f['time'].astype(str).str[7:]\n",
        "\n",
        "\n",
        "    interval = f.copy()\n",
        "    interval['time2'] = interval['time2'].astype(str).replace('','00:00:00')\n",
        "    interval['bus_route_id'] = interval['bus_route_id'].astype(object)\n",
        "\n",
        "    time4 = []\n",
        "\n",
        "    for i in interval['time2'] :\n",
        "\n",
        "        time4.append(get_sec(i))\n",
        "\n",
        "    interval['time4'] = time4\n",
        "    interval['time4'] = (interval['time4'] / 60).astype(int)\n",
        "\n",
        "    interval = interval[interval['time4'] &gt; 3] # 간격이 3분보다 작은 것 제외 \n",
        "    interval = interval[interval['time4'] &lt; 180] # 간격이 3시간보다 큰 것 제외\n",
        "\n",
        "    interval = interval.groupby('bus_route_id')['time4'].agg([('bus_interval', 'mean')]).reset_index()\n",
        "    interval['bus_interval'] = interval['bus_interval'].astype(int)\n",
        "\n",
        "    # 나중에 시간을 절약하기 위해 csv 파일로 저장\n",
        "    interval.to_csv('bus_interval_final.csv', index = False)\n",
        "\n",
        "    print('success.. !')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9VWnZXuYshl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bus_interval()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIYGQwSgYslf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 이 과정은 상당히 오래걸리는 관계로 따로 데이터셋을 만들어서 구성해놓았습니다.\n",
        "bus_interval = pd.read_csv(\"bus_interval_final.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4Y2XD5PYsp4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['bus_route_id'] = data['bus_route_id'].astype(np.int64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7GIWXIAYsty",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.merge(data, bus_interval, how = 'left', on = 'bus_route_id')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbBomigRcRQC",
        "colab_type": "text"
      },
      "source": [
        "'bus_interval'컬럼에서 na값을 가지는 행들을 분석해본 결과, 대부분 18~20시의 탑승 인원이 거의 없는 bus_route_id 와 station_code 였다. 따라서 탑승 인원이 별로 없을 것이라고 예상되는 버스는 배차 간격이 길 것이라고 판단하여 na값을 '9999' 로 채워주었다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IOp1U0CYs3u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['bus_interval'] = data['bus_interval'].fillna(9999)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WTPuJ576caYI",
        "colab_type": "text"
      },
      "source": [
        "# Label encoding feature\n",
        "#### bus_route_id, station_name, route_station_weekday(bus_route_id + weekday의 조합), route_station(bus_route_id + station_code 의 조합) 총 4개를 라벨인코딩 해줌"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZOGbKeTYs7i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labelencoder = LabelEncoder()\n",
        "df_encode = data[['bus_route_id','station_code', 'route_station_weekday', 'route_station']]\n",
        "df_encoded = df_encode.apply(labelencoder.fit_transform)\n",
        "\n",
        "data['bus_route_id2']=df_encoded['bus_route_id']\n",
        "data['station_code2']=df_encoded['station_code']\n",
        "data['route_station_weekday2']=df_encoded['route_station_weekday']\n",
        "data['route_station2']=df_encoded['route_station']\n",
        "\n",
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsbOuqp_Ys0W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# weather\n",
        "def weather() :\n",
        "\n",
        "    weather_data = pd.read_csv('weather.csv', encoding = 'utf-8')\n",
        "    weather_data['id'] = range(0,46)\n",
        "\n",
        "    a = pd.DataFrame(data.date.unique(), columns=['date']) ; a['id'] = range(0,46)\n",
        "    weather_data = pd.merge(a, weather_data)\n",
        "    weather_data = weather_data[['date','현재일기_10','체감온도_10','일강수_10']]\n",
        "    weather_data = weather_data.replace(' ', 0)\n",
        "    df = pd.merge(data, weather_data, on='date')\n",
        "    # label_encoder\n",
        "    labelencoder = LabelEncoder()\n",
        "    df_encode = df[['현재일기_10']]\n",
        "    df_encoded = df_encode.apply(labelencoder.fit_transform)\n",
        "    df['현재일기_10']=df_encoded['현재일기_10']\n",
        "    # object-&gt;float 변수변환\n",
        "    df['현재일기_10'] = df['현재일기_10'].astype(float)\n",
        "    df['체감온도_10'] = df['체감온도_10'].astype(float)\n",
        "    df['일강수_10'] = df['일강수_10'].astype(float)\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnRxqa_yYsem",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = weather()\n",
        "\n",
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-oBmDIJVYsbm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# weekday (data)\n",
        "data['date'] = pd.to_datetime(data['date'])\n",
        "data['weekday'] = data['date'].dt.weekday\n",
        "data = pd.get_dummies(data,columns=['weekday'])\n",
        "data['weekday'] = data['date'].dt.weekday\n",
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TZS5jX8cpZx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# in - out\n",
        "data['in_out'].value_counts()\n",
        "data['in_out'] = data['in_out'].map({'시내':0,'시외':1})\n",
        "\n",
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-e4NRr8cppO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 좌표데이터를 이용 변수\n",
        "# 좌표데이터를 이용한 변수를 만들 때는 많은 시간이 소요됩니다.\n",
        "coords_jejusi = (33.500770, 126.522761) #제주시의 위도 경도\n",
        "data['dis_jejusi'] = [geopy.distance.vincenty((data['latitude'].iloc[i],data['longitude'].iloc[i]), coords_jejusi).km for i in range(len(data))]\n",
        "\n",
        "coords_jejusicheong1 = (33.49892, 126.53035) #제주시청(광양방면)의 위도 경도\n",
        "coords_jejuairport = (33.50661, 126.49345) #제주국제공항(구제주방면)의 위도 경도\n",
        "coords_hallahosp = (33.48963, 126.486) #한라병원의 위도 경도\n",
        "coords_rotary = (33.49143, 126.49678) # 제주도청신제주로터리의 위도 경도\n",
        "coords_jejucenterhigh = (33.48902, 126.5392) #제주중앙여자고등학교의 위도 경도\n",
        "coords_jejumarket = (33.51315, 126.52706) #동문시장의 위도 경도\n",
        "coords_jejusclass = (33.47626, 126.48141) #제주고등학교/중흥S클래스의 위도 경도\n",
        "coords_centerroad = (33.51073, 126.5239) #중앙로(국민은행)의 위도 경도\n",
        "coords_fiveway = (33.48667, 126.48092) # 노형오거리의 위도 경도\n",
        "coords_law = (33.49363, 126.53476) # 제주지방법원(광양방면)의 위도 경도\n",
        "\n",
        "data['dis_jejusicheong1'] = [geopy.distance.vincenty((data['latitude'].iloc[i],data['longitude'].iloc[i]), coords_jejusicheong1).km for i in range(len(data))]\n",
        "data['dis_jejuairport'] = [geopy.distance.vincenty((data['latitude'].iloc[i],data['longitude'].iloc[i]), coords_jejuairport).km for i in range(len(data))]\n",
        "data['dis_hallahosp'] = [geopy.distance.vincenty((data['latitude'].iloc[i],data['longitude'].iloc[i]), coords_hallahosp).km for i in range(len(data))]\n",
        "data['dis_rotary'] = [geopy.distance.vincenty((data['latitude'].iloc[i],data['longitude'].iloc[i]), coords_rotary).km for i in range(len(data))]\n",
        "data['dis_jejucenterhigh'] = [geopy.distance.vincenty((data['latitude'].iloc[i],data['longitude'].iloc[i]), coords_jejucenterhigh).km for i in range(len(data))]\n",
        "data['dis_jejumarket'] = [geopy.distance.vincenty((data['latitude'].iloc[i],data['longitude'].iloc[i]), coords_jejumarket).km for i in range(len(data))]\n",
        "data['dis_jejusclass'] = [geopy.distance.vincenty((data['latitude'].iloc[i],data['longitude'].iloc[i]), coords_jejusclass).km for i in range(len(data))]\n",
        "data['dis_centerroad'] = [geopy.distance.vincenty((data['latitude'].iloc[i],data['longitude'].iloc[i]), coords_centerroad).km for i in range(len(data))]\n",
        "data['dis_fiveway'] = [geopy.distance.vincenty((data['latitude'].iloc[i],data['longitude'].iloc[i]), coords_fiveway).km for i in range(len(data))]\n",
        "data['dis_law'] = [geopy.distance.vincenty((data['latitude'].iloc[i],data['longitude'].iloc[i]), coords_law).km for i in range(len(data))]\n",
        "\n",
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVHM0H9pcpxp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 출근 시간의 총 승객 수\n",
        "data['ride_sum'] = data['6~7_ride'] + data['7~8_ride'] + data['8~9_ride'] + data['9~10_ride'] + data['10~11_ride'] + data['11~12_ride'] \n",
        "data['takeoff_sum'] = data['6~7_takeoff'] + data['7~8_takeoff'] + data['8~9_takeoff'] + data['9~10_takeoff'] + data['10~11_takeoff'] + data['11~12_takeoff'] \n",
        "\n",
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fDiF13Q7cpuH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 날짜 및 시간대 별 총 승객수\n",
        "f = data.groupby('date')['6~7_ride'].agg([('6~7_all_ride_number', 'sum')]).reset_index()\n",
        "data = pd.merge(data, f, how='left')\n",
        "\n",
        "f = data.groupby('date')['7~8_ride'].agg([('7~8_all_ride_number', 'sum')]).reset_index()\n",
        "data = pd.merge(data, f, how='left')\n",
        "\n",
        "f = data.groupby('date')['8~9_ride'].agg([('8~9_all_ride_number', 'sum')]).reset_index()\n",
        "data = pd.merge(data, f, how='left')\n",
        "\n",
        "f = data.groupby('date')['9~10_ride'].agg([('9~10_all_ride_number', 'sum')]).reset_index()\n",
        "data = pd.merge(data, f, how='left')\n",
        "\n",
        "f = data.groupby('date')['10~11_ride'].agg([('10~11_all_ride_number', 'sum')]).reset_index()\n",
        "data = pd.merge(data, f, how='left')\n",
        "\n",
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PDo4rnMcptY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 주말, 주중\n",
        "def h(x):\n",
        "    if x ==5:\n",
        "        return 1\n",
        "    elif x==6:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PblNH6Cgcpl8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['weekend'] = data['weekday'].apply(h)\n",
        "\n",
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3AK24Phcplg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 연휴\n",
        "def g(x):\n",
        "    if x in ['2019-09-12','2019-09-13','2019-09-14','2019-10-03','2019-10-09']:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6tv07kdcph3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['holiday'] = data['date'].apply(g) \n",
        "\n",
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "008OkrV2cpeL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 요일 별 평균 승객 수\n",
        "def week_mean() :\n",
        "\n",
        "    df = data.reset_index(drop=True)\n",
        "    df.groupby('weekday')['18~20_ride'].mean()\n",
        "    df['weekdaymean']= 1\n",
        "\n",
        "    index0 = df.query('weekday==0').index\n",
        "    index1 = df.query('weekday==1').index\n",
        "    index2 = df.query('weekday==2').index\n",
        "    index3 = df.query('weekday==3').index\n",
        "    index4 = df.query('weekday==4').index\n",
        "    index5 = df.query('weekday==5').index\n",
        "    index6 = df.query('weekday==6').index\n",
        "\n",
        "    df.iloc[index0,-1] = 1.343710\n",
        "    df.iloc[index1,-1] = 1.375319\n",
        "    df.iloc[index2,-1] = 1.430856\n",
        "    df.iloc[index3,-1] = 1.256710\n",
        "    df.iloc[index4,-1] = 1.067439\n",
        "    df.iloc[index5,-1] = 1.062123\n",
        "    df.iloc[index6,-1] = 1.034282\n",
        "\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9wFWrjYdE1S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = week_mean()\n",
        "\n",
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwOZh-dRdFDY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 시내 및 시외버스 별 평균 탑승 승객\n",
        "data['in_out_mean'] = 1\n",
        "inindex = data.query('in_out == \"시내\"').index\n",
        "outindex = data.query('in_out == \"시외\"').index\n",
        "\n",
        "data.iloc[inindex,-1] = 1.228499\n",
        "data.iloc[outindex,-1] = 2.044345\n",
        "data['congestion'] = data['congestion'].astype('int64')\n",
        "\n",
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMNCm7phdFNT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 카테고리별 승객 수\n",
        "def category_people() :\n",
        "    bts['bus_route_id'] = bts['bus_route_id'].astype(str)\n",
        "\n",
        "    f = bts.groupby(['bus_route_id','user_category'])['user_count'].agg([('승객수', 'sum')]).reset_index()\n",
        "\n",
        "    g = pd.pivot_table(f, values='승객수', index='bus_route_id', columns='user_category',fill_value=0).reset_index()\n",
        "    g.columns = ['bus_route_id', 'adult','kids','teen','elder','jang','jang2','ugong','ugong2']\n",
        "    g = g[['bus_route_id', 'adult','kids','teen','elder']]\n",
        "\n",
        "    # merge\n",
        "    df = pd.merge(data, g, how='left', on='bus_route_id')\n",
        "\n",
        "    # na preprocessing -&gt; mean value\n",
        "    df['adult'] = df['adult'].fillna(2363.077778)\n",
        "    df['kids'] = df['kids'].fillna(60.426984)\n",
        "    df['teen'] = df['teen'].fillna(448.277778)\n",
        "    df['elder'] = df['elder'].fillna(751.309524)\n",
        "                 \n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3B90l8I3dFI5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['bus_route_id'] = data['bus_route_id'].astype(str)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1qxwSRQdFE4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = category_people()\n",
        "\n",
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCTN5EF5dE_S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Category별 승객의 비율\n",
        "def category_people_ratio() :\n",
        "    \n",
        "    a = bts.groupby('bus_route_id')['user_count'].agg([('전체', 'sum')]).reset_index()\n",
        "    b = bts.groupby(['bus_route_id','user_category'])['user_count'].agg([('승객수', 'sum')]).reset_index()\n",
        "\n",
        "    c = pd.merge(b, a, on='bus_route_id')\n",
        "    c['비율'] = c['승객수']/c['전체']\n",
        "    c = pd.pivot_table(c, values='비율', index='bus_route_id', columns='user_category',fill_value=0).reset_index()\n",
        "    c.columns = ['bus_route_id', 'adult_prop','kids_prop','teen_prop','elder_prop','jang_prop','jang2_prop','ugong_prop','ugong2_prop']\n",
        "    f = c[['bus_route_id', 'adult_prop','kids_prop','teen_prop','elder_prop']]\n",
        "\n",
        "    df = pd.merge(data, f, how='left', on='bus_route_id')\n",
        "\n",
        "    # na preprocessing -&gt; mean value\n",
        "    df['adult_prop'] = df['adult_prop'].fillna(0.549702)\n",
        "    df['kids_prop'] = df['kids_prop'].fillna(60.426984)\n",
        "    df['teen_prop'] = df['teen_prop'].fillna(0.019902)\n",
        "    df['elder_prop'] = df['elder_prop'].fillna(0.235848)\n",
        "\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAlAwPprdE-x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ategory_people_ratio()\n",
        "\n",
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_V6qqUcdE6d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 각 동,읍,면별 직업군별 비율, 평균소득액, 평균소비액\n",
        "# jeju_finantial_life_data (외부데이터) 사용하여 피쳐 생성\n",
        "# train, test 데이터의 'latitude', 'longitude'열, jeju_financial_life_data의 'X_AXIS', 'Y_AXIS'열을 지오코딩 프로그램을 사용하여 주소로 변환하였다. \n",
        "# 변환한 주소를 전처리 하여 동 기준으로 두 데이터를 합쳐주었다. 그 뒤 파생변수를 생성하였다.\n",
        "# data_address.csv는 data의 주소가, life_address.csv는 jeju_finantial_life_data의 주소가 담겨있다.\n",
        "\n",
        "def jeoju_love() :\n",
        "    \n",
        "    loc_data = pd.read_csv(\"data_address.csv\", encoding='cp949')\n",
        "    loc_life = pd.read_csv(\"life_address.csv\", encoding='cp949')\n",
        "    \n",
        "    loc_data = loc_data[['location','dong', 'si']]\n",
        "    loc_life = loc_life[['location','dong', 'si']]\n",
        "\n",
        "    df = pd.merge(data, loc_data, how='left', on='location')\n",
        "    \n",
        "    jeju_life = pd.read_csv(\"jeju_financial_life_data.csv\")\n",
        "    jeju_life['location'] = jeju_life['x_axis'].astype(str).str[:10] + ',' + jeju_life['y_axis'].astype(str).str[:10]\n",
        "    jeju_life2 = pd.merge(jeju_life, loc_life, how='left', on='location')\n",
        "\n",
        "    dong_f1 = jeju_life2.groupby(['dong'])[['job_majorc', 'job_smallc', 'job_public', 'job_profession', 'job_self','vehicle_own_rat', 'avg_income', 'med_income', 'avg_spend']].mean().reset_index()\n",
        "    dong_f1.columns=['dong','mean_job_majorc', 'mean_job_smallc', 'mean_job_public', 'mean_job_profession', 'mean_job_self','mean_vehicle_own_rat', 'mean_avg_income', 'mean_med_income', 'mean_avg_spend']\n",
        "\n",
        "    dong_f2 = jeju_life2.groupby(['dong'])[['job_majorc', 'job_smallc', 'job_public', 'job_profession', 'job_self','vehicle_own_rat', 'avg_income', 'med_income', 'avg_spend']].sum().reset_index()\n",
        "    dong_f2.columns=['dong','sum_job_majorc', 'sum_job_smallc', 'sum_job_public', 'sum_job_profession', 'sum_job_self','sum_vehicle_own_rat', 'sum_avg_income', 'sum_med_income', 'sum_avg_spend']\n",
        "\n",
        "    dong_f3 = (jeju_life2.groupby(['dong'])['job_majorc', 'job_smallc', 'job_public', 'job_profession', 'job_self','vehicle_own_rat', 'avg_income', 'med_income', 'avg_spend'].sum()/jeju_life2.groupby(['dong'])['job_majorc', 'job_smallc', 'job_public', 'job_profession', 'job_self','vehicle_own_rat', 'avg_income', 'med_income', 'avg_spend'].sum().sum()).reset_index()\n",
        "    dong_f3.columns = ['dong','rate_job_majorc', 'rate_job_smallc', 'rate_job_public', 'rate_job_profession', 'rate_job_self','rate_vehicle_own_rat', 'rate_avg_income', 'rate_med_income', 'rate_avg_spend']\n",
        "\n",
        "    m_1 = pd.merge(dong_f1, dong_f2, how='left', on='dong')\n",
        "    m_2 = pd.merge(m_1, dong_f3, how='left', on='dong')\n",
        "    df = pd.merge(df, m_2, how='left', on='dong')\n",
        "\n",
        "    #  # na preprocessing -&gt; mean value\n",
        "    df['mean_job_majorc'] = df['mean_job_majorc'].fillna(0.024219)\n",
        "    df['mean_job_smallc'] = df['mean_job_smallc'].fillna(0.145757)\n",
        "    df['mean_job_public'] = df['mean_job_public'].fillna(0.032768)\n",
        "    df['mean_job_profession'] = df['mean_job_profession'].fillna(0.014855)\n",
        "    df['mean_job_self'] = df['mean_job_self'].fillna(0.222090)\n",
        "    df['mean_vehicle_own_rat'] = df['mean_vehicle_own_rat'].fillna(0.041161)\n",
        "    df['mean_avg_income'] = df['mean_avg_income'].fillna(34221420)\n",
        "    df['mean_med_income'] = df['mean_med_income'].fillna(30645290)\n",
        "    df['mean_avg_spend'] = df['mean_avg_spend'].fillna(4224923)\n",
        "\n",
        "    df['sum_job_majorc'] = df['sum_job_majorc'].fillna(3.717861e+00)\n",
        "    df['sum_job_smallc'] = df['sum_job_smallc'].fillna(2.078142e+01)\n",
        "    df['sum_job_public'] = df['sum_job_public'].fillna(4.747755e+00)\n",
        "    df['sum_job_profession'] = df['sum_job_profession'].fillna(2.169554e+00)\n",
        "    df['sum_job_self'] = df['sum_job_self'].fillna(3.044199e+01)\n",
        "    df['sum_vehicle_own_rat'] = df['sum_vehicle_own_rat'].fillna(5.609080e+00)\n",
        "    df['sum_avg_income'] = df['sum_avg_income'].fillna(4.998226e+09)\n",
        "    df['sum_med_income'] = df['sum_med_income'].fillna(4.455924e+09)\n",
        "    df['sum_avg_spend'] = df['sum_avg_spend'].fillna(6.147678e+08)\n",
        "\n",
        "    df['rate_job_majorc'] = df['rate_job_majorc'].fillna(1.388889e-02)\n",
        "    df['rate_job_smallc'] = df['rate_job_smallc'].fillna(1.388889e-02)\n",
        "    df['rate_job_public'] = df['rate_job_public'].fillna(1.388889e-02)\n",
        "    df['rate_job_profession'] = df['rate_job_profession'].fillna(1.388889e-02)\n",
        "    df['rate_job_self'] = df['rate_job_self'].fillna(1.388889e-02)\n",
        "    df['rate_vehicle_own_rat'] = df['rate_vehicle_own_rat'].fillna(1.388889e-02)\n",
        "    df['rate_avg_income'] = df['rate_avg_income'].fillna(1.388889e-02)\n",
        "    df['rate_med_income'] = df['rate_med_income'].fillna(1.388889e-02)\n",
        "    df['rate_avg_spend'] = df['rate_avg_spend'].fillna(1.388889e-02)\n",
        "\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDVVRwpRdfpd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = jeoju_love()\n",
        "\n",
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhN9vPi5df7O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 수요가 많을 것으로 예상되는 정류장\n",
        "g = data[data['station_name'].str.contains('고등학교')]\n",
        "highschool = list(g['station_name'].unique())\n",
        "\n",
        "g = data[data['station_name'].str.contains('대학교')]\n",
        "university = list(g['station_name'].unique())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1F5Cl8Jgdf6r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def f(x):\n",
        "    if x in highschool:\n",
        "        return 1\n",
        "    elif x in university:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buqt-AUzdf1v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['school'] = data['station_name'].apply(f) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNnANpy7df1N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "g = data[data['station_name'].str.contains('환승')]\n",
        "transfer = list(g['station_name'].unique())\n",
        "\n",
        "g = data[data['station_name'].str.contains('공항')]\n",
        "airport = list(g['station_name'].unique())\n",
        "\n",
        "g = data[data['station_name'].str.contains('터미널')]\n",
        "terminal = list(g['station_name'].unique())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V24XvZildfwO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def f(x):\n",
        "    if x in transfer:\n",
        "        return 1\n",
        "    elif x in airport:\n",
        "        return 1\n",
        "    elif x in terminal:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWodu7TBdfvo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['transfer'] = data['station_name'].apply(f) \n",
        "\n",
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfcfh_8edq_a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 동 - 라벨인코딩\n",
        "labelencoder = LabelEncoder()\n",
        "df_encode = data[['dong']]\n",
        "df_encoded = df_encode.apply(labelencoder.fit_transform)\n",
        "\n",
        "data['dong2']=df_encoded['dong']\n",
        "\n",
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWvsiT5XdrUP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 측정소와 정류장 사이 거리 계산\n",
        "def dist() :\n",
        "    jeju=(33.51411, 126.52969) # 제주 측정소 근처\n",
        "    gosan=(33.29382, 126.16283) #고산 측정소 근처\n",
        "    seongsan=(33.38677, 126.8802) #성산 측정소 근처\n",
        "    po=(33.24616, 126.5653) #서귀포 측정소 근처\n",
        "\n",
        "    t1 = [geopy.distance.vincenty( (i,j), jeju).km for i,j in list( zip( data['latitude'],data['longitude'] )) ]\n",
        "    t2 = [geopy.distance.vincenty( (i,j), gosan).km for i,j in list( zip( data['latitude'],data['longitude'] )) ]\n",
        "    t3 = [geopy.distance.vincenty( (i,j), seongsan).km for i,j in list( zip( data['latitude'],data['longitude'] )) ]\n",
        "    t4 = [geopy.distance.vincenty( (i,j), po).km for i,j in list( zip( data['latitude'],data['longitude'] )) ]\n",
        "\n",
        "    data['dis_jeju'] = t1\n",
        "    data['dis_gosan']=t2\n",
        "    data['dis_seongsan']=t3\n",
        "    data['dis_po']=t4\n",
        "\n",
        "    total = pd.DataFrame(list(zip( t1,t2,t3,t4)),columns=['jeju','gosan','seongsan','po'] )\n",
        "    data['dist_name'] = total.apply(lambda x: x.argmin(), axis=1)\n",
        "    \n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmfXJWCVdrTz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = dist()\n",
        "\n",
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvG8fVmVdrOk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 날씨 관련 변수\n",
        "# 중급자코드를 참고하면 rain3.csv를 만들 수 있다.\n",
        "rain3 = pd.read_csv(\"rain3.csv\")\n",
        "\n",
        "# train, test의 변수명과 통일시키고, NaN의 값은 0.0000으로 변경\n",
        "rain3 = rain3.rename(columns={\"일시\":\"date\",\"지점\":\"dist_name\"})\n",
        "rain3 = rain3.fillna(0.00000)\n",
        "rain3['date'] = pd.to_datetime(rain3['date'])\n",
        "\n",
        "rain3.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPWl-FQHdrOG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.merge(data, rain3, how='left',on=['dist_name','date'])\n",
        "data = pd.get_dummies(data,columns=['dist_name'])\n",
        "data = pd.get_dummies(data,columns=['si'])\n",
        "\n",
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnQm5n49drMk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# rainy_day\n",
        "# 비 오는날=1, 비 안오는 날=0\n",
        "def f(x):\n",
        "    if x == 0:\n",
        "        return 0\n",
        "    else:\n",
        "        return 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IK_8oNildrGi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['rainy_day'] = data['강수량(mm)'].apply(f)\n",
        "\n",
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dyatf7RfdrF-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 승 하차 시간대 통합 변수 (t ~ t+3)\n",
        "# t~t+1, t+1~t+2, t+2~t+3 시간대 승하차인원을 합하여 t~t+3 시간대 승하차인원 변수를 만듬\n",
        "data['69a'] = data['6~7_ride']+data['7~8_ride']+data['8~9_ride']\n",
        "data['912a']=data['9~10_ride']+data['10~11_ride']+data['11~12_ride']\n",
        "\n",
        "data['69b'] = data['6~7_takeoff']+data['7~8_takeoff']+data['8~9_takeoff']\n",
        "data['912b'] = data['9~10_takeoff']+data['10~11_takeoff']+data['11~12_takeoff']\n",
        "\n",
        "data.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbvWkzSzd-LZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# MAKE DATASET\n",
        "# train, test 데이터를 만들어준다.\n",
        "train_data = data.query('cue==\"0\"').reset_index()\n",
        "test_data = data.query('cue==\"1\"').reset_index()\n",
        "\n",
        "train_data.shape, test_data.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9D-dg7Aed-e7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 요약통계량을 통한 변수를 만드는 과정에서 NA가 발생한다.\n",
        "\n",
        "# target variable을 분리한 후 데이터를 저장한다.\n",
        "y_train = train_data[['18~20_ride']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZ71E1zld-lg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data.shape, test_data.shape, y_train.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVDM1_JKd-eY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data.to_csv('X_train.csv', index = False, encoding = 'utf-8')\n",
        "test_data.to_csv('X_test.csv', index = False, encoding = 'utf-8')\n",
        "y_train.to_csv('y_train.csv', index = False, encoding = 'utf-8')\n",
        "\n",
        "print('save ..!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPubOo0fd-d7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = pd.read_csv('X_train.csv', encoding = 'utf-8')\n",
        "test_data = pd.read_csv('X_test.csv', encoding = 'utf-8')\n",
        "y_train = pd.read_csv('y_train.csv', encoding = 'utf-8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzhHQtzrd-YT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# COLUMNS\n",
        "input_var_0=['in_out','latitude','longitude','6~7_ride', '7~8_ride', '8~9_ride', '9~10_ride', '10~11_ride', '11~12_ride',\n",
        "           '6~7_takeoff', '7~8_takeoff', '8~9_takeoff', '9~10_takeoff', '10~11_takeoff', '11~12_takeoff',\n",
        "           'weekday_0', 'weekday_1', 'weekday_2', 'weekday_3', 'weekday_4', 'weekday_5', 'weekday_6', \n",
        "           'dis_jejusi', 'dis_jejusicheong1','dis_jejuairport','dis_hallahosp', 'dis_rotary','dis_jejucenterhigh',\n",
        "           'dis_jejumarket', 'dis_centerroad', 'dis_jejusclass', 'dis_fiveway', 'dis_law',\n",
        "           'weekend', 'holiday', 'ride_sum', 'takeoff_sum', '1820_rs_mean', '1820_r_mean', '1820_s_mean', 'congestion',\n",
        "           'station_code2', 'bus_route_id2', '일강수_10', '현재일기_10', '체감온도_10',\n",
        "           '6~7_all_ride_number', '7~8_all_ride_number', '8~9_all_ride_number', '9~10_all_ride_number', '10~11_all_ride_number',\n",
        "           '1820_w_mean','in_out_mean','weekdaymean','adult','kids','teen','elder','adult_prop', 'kids_prop', 'teen_prop', 'elder_prop',\n",
        "           'mean_job_majorc', 'mean_job_smallc', 'mean_job_public', 'mean_job_profession', 'mean_job_self',\n",
        "           'mean_vehicle_own_rat', 'mean_avg_income', 'mean_med_income', 'mean_avg_spend', \n",
        "           'rate_job_majorc', 'rate_job_smallc', 'rate_job_public', 'rate_job_profession', 'rate_job_self', \n",
        "           'rate_vehicle_own_rat', 'rate_avg_income', 'rate_med_income','rate_avg_spend',\n",
        "           'sum_job_majorc', 'sum_job_smallc', 'sum_job_public', 'sum_job_profession', 'sum_job_self', \n",
        "           'sum_vehicle_own_rat', 'sum_avg_income', 'sum_med_income','sum_avg_spend',\n",
        "           '68a', '810a', '1012a', '68b', '810b', '1012b','69a','912a','69b','912b',\n",
        "           'dis_jeju', 'dis_gosan', 'dis_seongsan', 'dis_po', '기온(°C)', '강수량(mm)',\n",
        "           'dist_name_gosan', 'dist_name_jeju', 'dist_name_po', 'dist_name_seongsan', 'si_서귀포시', 'si_제주시',\n",
        "           'school', 'transfer', 'dong2', 'rainy_day']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyuqpSgVd-X2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_var_1=['in_out','latitude','longitude','6~7_ride', '7~8_ride', '8~9_ride', '9~10_ride', '10~11_ride', '11~12_ride',\n",
        "           '6~7_takeoff', '7~8_takeoff', '8~9_takeoff', '9~10_takeoff', '10~11_takeoff', '11~12_takeoff',\n",
        "           'weekday_0', 'weekday_1', 'weekday_2', 'weekday_3', 'weekday_4', 'weekday_5', 'weekday_6', \n",
        "           'dis_jejusi', 'dis_jejusicheong1','dis_jejuairport','dis_hallahosp', 'dis_rotary','dis_jejucenterhigh',\n",
        "           'dis_jejumarket', 'dis_centerroad', 'dis_jejusclass', 'dis_fiveway', 'dis_law',\n",
        "           'weekend', 'holiday', 'ride_sum', 'takeoff_sum', '1820_rs_mean', '1820_r_mean', '1820_s_mean', 'congestion',\n",
        "           'station_code2', 'bus_route_id2', '일강수_10', '현재일기_10', '체감온도_10',\n",
        "           '6~7_all_ride_number', '7~8_all_ride_number', '8~9_all_ride_number', '9~10_all_ride_number', '10~11_all_ride_number',\n",
        "           '1820_w_mean','in_out_mean','weekdaymean','adult','kids','teen','elder','adult_prop', 'kids_prop', 'teen_prop', 'elder_prop',\n",
        "           'mean_job_majorc', 'mean_job_smallc', 'mean_job_public', 'mean_job_profession', 'mean_job_self',\n",
        "           'mean_vehicle_own_rat', 'mean_avg_income', 'mean_med_income', 'mean_avg_spend', \n",
        "           'rate_job_majorc', 'rate_job_smallc', 'rate_job_public', 'rate_job_profession', 'rate_job_self', \n",
        "           'rate_vehicle_own_rat', 'rate_avg_income', 'rate_med_income','rate_avg_spend',\n",
        "           'sum_job_majorc', 'sum_job_smallc', 'sum_job_public', 'sum_job_profession', 'sum_job_self', \n",
        "           'sum_vehicle_own_rat', 'sum_avg_income', 'sum_med_income','sum_avg_spend',\n",
        "           '68a', '810a', '1012a', '68b', '810b', '1012b','69a','912a','69b','912b',\n",
        "           'dis_jeju', 'dis_gosan', 'dis_seongsan', 'dis_po', '기온(°C)', '강수량(mm)',\n",
        "           'dist_name_gosan', 'dist_name_jeju', 'dist_name_po', 'dist_name_seongsan', 'si_서귀포시', 'si_제주시',\n",
        "           'school', 'transfer', 'dong2', 'rainy_day']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-385wCbDd-Sc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_var_2=['in_out','latitude','longitude','6~7_ride', '7~8_ride', '8~9_ride', '9~10_ride', '10~11_ride', '11~12_ride',\n",
        "           '6~7_takeoff', '7~8_takeoff', '8~9_takeoff', '9~10_takeoff', '10~11_takeoff', '11~12_takeoff',\n",
        "           'weekday_0', 'weekday_1', 'weekday_2', 'weekday_3', 'weekday_4', 'weekday_5', 'weekday_6', \n",
        "           'dis_jejusi', 'dis_jejusicheong1','dis_jejuairport','dis_hallahosp', 'dis_rotary','dis_jejucenterhigh',\n",
        "           'dis_jejumarket', 'dis_centerroad', 'dis_jejusclass', 'dis_fiveway', 'dis_law',\n",
        "           'weekend', 'holiday', 'ride_sum', 'takeoff_sum', '1820_rs_mean', '1820_r_mean', '1820_s_mean', 'congestion',\n",
        "           'station_code2', 'bus_route_id2', '일강수_10', '현재일기_10', '체감온도_10',\n",
        "           '6~7_all_ride_number', '7~8_all_ride_number', '8~9_all_ride_number', '9~10_all_ride_number', '10~11_all_ride_number',\n",
        "           '1820_w_mean','in_out_mean','weekdaymean','adult','kids','teen','elder','adult_prop', 'kids_prop', 'teen_prop', 'elder_prop',\n",
        "           'mean_job_majorc', 'mean_job_smallc', 'mean_job_public', 'mean_job_profession', 'mean_job_self',\n",
        "           'mean_vehicle_own_rat', 'mean_avg_income', 'mean_med_income', 'mean_avg_spend', \n",
        "           'rate_job_majorc', 'rate_job_smallc', 'rate_job_public', 'rate_job_profession', 'rate_job_self', \n",
        "           'rate_vehicle_own_rat', 'rate_avg_income', 'rate_med_income','rate_avg_spend',\n",
        "           'sum_job_majorc', 'sum_job_smallc', 'sum_job_public', 'sum_job_profession', 'sum_job_self', \n",
        "           'sum_vehicle_own_rat', 'sum_avg_income', 'sum_med_income','sum_avg_spend',\n",
        "           '68a', '810a', '1012a', '68b', '810b', '1012b','69a','912a','69b','912b',\n",
        "           'dis_jeju', 'dis_gosan', 'dis_seongsan', 'dis_po', '기온(°C)', '강수량(mm)',\n",
        "           'dist_name_gosan', 'dist_name_jeju', 'dist_name_po', 'dist_name_seongsan', 'si_서귀포시', 'si_제주시',\n",
        "           'school', 'transfer', 'dong2', 'rainy_day']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHyECipnd-R_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_var_3 =['in_out','latitude','longitude','6~7_ride', '7~8_ride', '8~9_ride', '9~10_ride', '10~11_ride', '11~12_ride',\n",
        "           '6~7_takeoff', '7~8_takeoff', '8~9_takeoff', '9~10_takeoff', '10~11_takeoff', '11~12_takeoff',\n",
        "           'weekday_0', 'weekday_1', 'weekday_2', 'weekday_3', 'weekday_4', 'weekday_5', 'weekday_6', \n",
        "           'dis_jejusi', 'dis_jejusicheong1','dis_jejuairport','dis_hallahosp', 'dis_rotary','dis_jejucenterhigh',\n",
        "           'dis_jejumarket', 'dis_centerroad', 'dis_jejusclass', 'dis_fiveway', 'dis_law',\n",
        "           'weekend', 'holiday', 'ride_sum', 'takeoff_sum', '1820_rs_mean', '1820_r_mean', '1820_s_mean', 'congestion',\n",
        "           'station_code2', 'bus_route_id2', '일강수_10', '현재일기_10', '체감온도_10',\n",
        "           '6~7_all_ride_number', '7~8_all_ride_number', '8~9_all_ride_number', '9~10_all_ride_number', '10~11_all_ride_number',\n",
        "           '1820_w_mean','in_out_mean','weekdaymean','adult','kids','teen','elder','adult_prop', 'kids_prop', 'teen_prop', \n",
        "           'elder_prop', 'mean_job_majorc', 'mean_job_smallc',\n",
        "           'mean_job_public', 'mean_job_profession', 'mean_job_self','mean_vehicle_own_rat',\n",
        "          '68a', '810a', '1012a', '68b', '810b', '1012b',\n",
        "          'dis_jeju', 'dis_gosan','dis_seongsan', 'dis_po','기온(°C)', '강수량(mm)', \n",
        "           'dist_name_gosan', 'dist_name_jeju','dist_name_po', 'dist_name_seongsan']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyBljFYde1c2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_var_4 = ['sum_avg_spend', '68a', '810a', 'si_제주시',  'dong2' , 'bus_interval', 'dis_jejuairport', 'ride_sum',\n",
        "             'takeoff_sum', '1820_rs_mean', '1820_rs_sum','1820_r_mean','1820_r_sum', '1820_s_mean',\n",
        "             '1820_s_sum','congestion', 'bus_route_id2', '6~7_all_ride_number', '7~8_all_ride_number',\n",
        "             '8~9_all_ride_number', '1012a_mean', '1012b_sum','10~11_ride_sum', '10~11_takeoff_sum', '11~12_ride_sum',\n",
        "             '11~12_takeoff_sum', '1820_r_mean_sum', '1820_r_mean_mean',\n",
        "             '1820_r_sum_sum', '1820_r_sum_mean', '1820_rs_mean_sum',\n",
        "             '1820_s_mean_sum', '1820_s_mean_mean', '1820_s_sum_sum',\n",
        "             '1820_s_sum_mean', '1820_w_mean_sum', '1820_w_mean_mean',\n",
        "             '1820_w_sum_mean', '68a_sum', '68a_mean', '68b_sum', 'in_out', 'latitude', 'longitude',\n",
        "             '6~7_ride', '7~8_ride', '8~9_ride', '9~10_ride', '10~11_ride', '11~12_ride', '6~7_takeoff', '7~8_takeoff',\n",
        "             '8~9_takeoff', '9~10_takeoff', '10~11_takeoff', '11~12_takeoff',\n",
        "             'weekday_0', 'weekday_1', 'weekday_2', 'weekday_3', 'weekday_4',\n",
        "             'weekday_5', 'weekday_6', 'dis_jejusi', '68b_mean', '6~7_ride_sum',\n",
        "             '6~7_ride_mean', '6~7_takeoff_sum', '6~7_takeoff_mean', '7~8_ride_sum',\n",
        "             '7~8_ride_mean', '7~8_takeoff_sum', '7~8_takeoff_mean', '810a_sum',\n",
        "             '810b_sum', '8~9_ride_sum', '8~9_takeoff_sum', '8~9_takeoff_mean',\n",
        "             '9~10_ride_sum', '9~10_takeoff_sum', 'route_station_weekday2']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n51V7NSue10S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 모델 학습 및 검증\n",
        "# TASK - 0\n",
        "lgbm = lgb.LGBMRegressor(num_iterations = 1000, \n",
        "                                learning_rate = 0.05,\n",
        "                                boosting = 'dart',\n",
        "                         Metric = 'regression_l2', n_jobs=-1)\n",
        "\n",
        "X = train_data[input_var_0]\n",
        "y = y_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odNqxpJYe1zy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X.columns=range(len(X.columns))\n",
        "\n",
        "lgbm.fit(X, y)\n",
        "\n",
        "y_pred = lgbm.predict(X)\n",
        "\n",
        "np.sqrt(mean_squared_error(y_train, y_pred))\n",
        "\n",
        "y_pred = lgbm.predict(test_data[input_var_0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aBmO3BvUe1tV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub = pd.read_csv('submission_sample.csv')\n",
        "sub['18~20_ride'] = y_pred\n",
        "sub.to_csv('lgbm0=229.csv', index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mNRvA1rDe1s3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TASK - 1\n",
        "rf = RandomForestRegressor(max_features=5,\n",
        "                           min_samples_leaf=1,\n",
        "                           min_samples_split=2,\n",
        "                           n_estimators=300,\n",
        "                           random_state=1217)\n",
        "\n",
        "X = train_data[input_var_1]\n",
        "y = y_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWCkcOQKe1sR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rf.fit(X, y)\n",
        "\n",
        "y_pred = rf.predict(train_data[input_var_1])\n",
        "\n",
        "np.sqrt(mean_squared_error(y_train, y_pred))\n",
        "\n",
        "y_pred = rf.predict(test_data[input_var_1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96MvkfcYf3p6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub = pd.read_csv('submission_sample.csv')\n",
        "sub['18~20_ride'] = y_pred\n",
        "sub.to_csv('rf1=234.csv', index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHQVItITe1lG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TASK - 2\n",
        "rf = RandomForestRegressor(random_state=1217,\n",
        "                           max_features= 3,\n",
        "                           min_samples_leaf= 2,\n",
        "                           min_samples_split=2,\n",
        "                           n_estimators=500)\n",
        "\n",
        "X = train_data[input_var_2]\n",
        "y = y_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wc8lHI06e1kh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rf.fit(X, y)\n",
        "\n",
        "y_pred = rf.predict(train_data[input_var_2])\n",
        "\n",
        "np.sqrt(mean_squared_error(y_train, y_pred))\n",
        "\n",
        "y_pred = rf.predict(test_data[input_var_2])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRzJlWhof5vE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub = pd.read_csv('submission_sample.csv')\n",
        "sub['18~20_ride'] = y_pred\n",
        "sub.to_csv('rf2=238.csv', index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taxkOWYkfcx2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TASK - 3\n",
        "rf = RandomForestRegressor(max_features=3,\n",
        "                           min_samples_leaf=2,\n",
        "                           min_samples_split=2,\n",
        "                           n_estimators=500,\n",
        "                           random_state=1217)\n",
        "\n",
        "X = train_data[input_var_3]\n",
        "y = y_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "occQxl0vfdK1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rf.fit(X, y)\n",
        "\n",
        "y_pred = rf.predict(train_data[input_var_3])\n",
        "\n",
        "np.sqrt(mean_squared_error(y_train, y_pred))\n",
        "\n",
        "y_pred = rf.predict(test_data[input_var_3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5T4woF_f74C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub = pd.read_csv('submission_sample.csv')\n",
        "sub['18~20_ride'] = y_pred\n",
        "sub.to_csv('rf3=236.csv', index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ivQfjBkXfdKR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TASK - 4\n",
        "rf = RandomForestRegressor(max_features=3,\n",
        "                           min_samples_leaf=2,\n",
        "                           min_samples_split=2,\n",
        "                           n_estimators=500,\n",
        "                           random_state=1217)\n",
        "\n",
        "X = train_data[input_var_4]\n",
        "y = y_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gh516lEfdDS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rf.fit(X, y)\n",
        "\n",
        "y_pred = rf.predict(train_data[input_var_4])\n",
        "\n",
        "np.sqrt(mean_squared_error(y_train, y_pred))\n",
        "\n",
        "y_pred = rf.predict(test_data[input_var_4])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7E3NBf6fdCw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sub = pd.read_csv('submission_sample.csv')\n",
        "sub['18~20_ride'] = y_pred\n",
        "sub.to_csv('rf4=231.csv', index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBBVAyELfdCQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ENSEMBLE\n",
        "# 변수별 성능 및 상관관계 확인\n",
        "items = []\n",
        "\n",
        "file_list = ['lgbm0=229.csv', 'rf1=234.csv', 'rf2=238.csv', 'rf3=236.csv', 'rf4=231.csv']\n",
        "\n",
        "for item in file_list :\n",
        "    if item.find('.csv') is not -1 :        \n",
        "        items.append(item)\n",
        "\n",
        "print(items)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePtGzIIjfc7S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(0, len(items)) :\n",
        "    \n",
        "    item = items[i]\n",
        "    df = pd.read_csv(item, engine = 'python').iloc[:,1:]\n",
        "    df.columns = [items[i]]\n",
        "    \n",
        "    if i == 0 :\n",
        "        corr_df = pd.DataFrame()\n",
        "        \n",
        "    corr_df = pd.concat([corr_df, df], axis = 1)\n",
        "\n",
        "    \n",
        "corr = np.array(corr_df.corr().mean(axis = 0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXHwZvbZfc6r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corr_df.corr()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_Ebq5hefc5_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rmse = []\n",
        "\n",
        "for i in range(0, len(items)) :\n",
        "    score = items[i].split('=')[-1][:6]\n",
        "    score = score.split('.')[0]\n",
        "    score = float(score)\n",
        "    rmse.append(score)\n",
        "    \n",
        "df = pd.DataFrame({'rnk': list(range(0, len(rmse))), 'rmse': rmse, 'cor': corr})\n",
        "df.index = items"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3PtNdDegQPp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.sort_values('cor', ascending = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TinZRASXgQkV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "g = sns.scatterplot(x=\"cor\", y=\"rmse\", data=df, s=30)\n",
        "\n",
        "for line in range(0, df.shape[0]):\n",
        "     g.text(df.cor[line]+0.00005 , df.rmse[line]-0.00003, \n",
        "            df.rnk[line], horizontalalignment='left', \n",
        "            size='medium', color='black', weight='semibold')\n",
        "        \n",
        "plt.xlim((df.cor.min()-0.00002,df.cor.max()+0.0002))\n",
        "plt.ylim((df.rmse.min()-0.0002,df.rmse.max()+0.0002))\n",
        "\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HkDkiVIgQj0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 멱평균\n",
        "\n",
        "# 앙상블은 별도의 jupyter 파일에서 진행합니다.\n",
        "\n",
        "# 첫 번 째 조합\n",
        "# Ensemble_1 폴더를 만든 후 lgbm0=229.csv, rf4=231.csv를 위치시킨다.\n",
        "# 두 파일을 멱평균을 실시한다.\n",
        "# p값은 21.2로 한다.\n",
        "os.mkdir('Ensemble_1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtmUOwP3gQcI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 경로를 위치시킨다.\n",
        "source_files = 'C:\\\\Users\\\\yena1\\\\Desktop\\\\3rd_Solution\\\\'\n",
        "destination_folder = 'C:\\\\Users\\\\yena1\\\\Desktop\\\\3rd_Solution\\\\Ensemble_1\\\\'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kx5Tq1wngQbk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shutil.move(source_files + 'lgbm0=229.csv', destination_folder + 'lgbm0=229.csv')\n",
        "shutil.move(source_files + 'rf4=231.csv', destination_folder + 'rf4=231.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uhjlu1QkgQbE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 두 번 째 조합\n",
        "# Ensemble_2 폴더를 만든 후 rf1=234.csv, rf3=236.csv를 위치시킨다.\n",
        "# 두 파일을 멱평균을 실시한다.\n",
        "# p값은 21.2로 한다.\n",
        "os.mkdir('Ensemble_2')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fo6Qx5--gQae",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "source_files = 'C:\\\\Users\\\\yena1\\\\Desktop\\\\3rd_solution\\\\'\n",
        "destination_folder = 'C:\\\\Users\\\\yena1\\\\Desktop\\\\3rd_solution\\\\Ensemble_2\\\\'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0xsYtKngoAa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "shutil.move(source_files + 'rf1=234.csv', destination_folder + 'rf1=234.csv')\n",
        "shutil.move(source_files + 'rf3=236.csv', destination_folder + 'rf3=236.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnJ36MEngoTI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 앙상블\n",
        "# 멱평균\n",
        "# 첫번째 조합\n",
        "\n",
        "# 사용법: \n",
        "# 1) 스크립트를 실행하기 전에 Ensemble 폴더를 먼저 만듭니다. \n",
        "# 2) 앙상블할 submission 화일을 Ensemble 폴더에 저장합니다.\n",
        "# 3) 실행하면 현재 폴더에 앙상블한 submission 화일이 생성됩니다.\n",
        "\n",
        "# 주) 이 스크립트는 Kaggle Kernel에서 실행할 수 없고 여러분의 Jupyter Notebook에서 실행해야 합니다.\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "folder = 'Ensemble_1'\n",
        "\n",
        "nf = 0\n",
        "for f in os.listdir(folder):\n",
        "    ext = os.path.splitext(f)[-1]\n",
        "    if ext == '.csv': \n",
        "        s = pd.read_csv(folder+\"/\"+f)\n",
        "    else: \n",
        "        continue\n",
        "    if len(s.columns) !=2:\n",
        "        continue\n",
        "    if nf == 0: \n",
        "        slist = s\n",
        "    else: \n",
        "        slist = pd.merge(slist, s, on=\"id\")\n",
        "    nf += 1\n",
        "\n",
        "# 이 파라미터는 멱평균 앙상블에 있어 중요한 수치임. 최적의 수치를 찾기 바랍니다.    \n",
        "p = 21\n",
        "\n",
        "if nf &gt;= 2:\n",
        "    pred = 0\n",
        "    for j in range(nf): pred = pred + slist.iloc[:,j+1]**p \n",
        "    pred = pred / nf    \n",
        "    pred = pred**(1/p)\n",
        "\n",
        "    submit = pd.DataFrame({'id': slist.id, '18~20_ride': pred})\n",
        "    t = pd.Timestamp.now()\n",
        "    fname = \"0+4.csv\"\n",
        "    submit.to_csv(fname, index=False)\n",
        "    \n",
        "    print(fname)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvzxIpnbgoR2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 두번째 조합\n",
        "# 사용법: \n",
        "# 1) 스크립트를 실행하기 전에 Ensemble 폴더를 먼저 만듭니다. \n",
        "# 2) 앙상블할 submission 화일을 Ensemble 폴더에 저장합니다.\n",
        "# 3) 실행하면 현재 폴더에 앙상블한 submission 화일이 생성됩니다.\n",
        "\n",
        "# 주) 이 스크립트는 Kaggle Kernel에서 실행할 수 없고 여러분의 Jupyter Notebook에서 실행해야 합니다.\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "folder = 'Ensemble_2'\n",
        "\n",
        "nf = 0\n",
        "for f in os.listdir(folder):\n",
        "    ext = os.path.splitext(f)[-1]\n",
        "    if ext == '.csv': \n",
        "        s = pd.read_csv(folder+\"/\"+f)\n",
        "    else: \n",
        "        continue\n",
        "    if len(s.columns) !=2:\n",
        "        continue\n",
        "    if nf == 0: \n",
        "        slist = s\n",
        "    else: \n",
        "        slist = pd.merge(slist, s, on=\"id\")\n",
        "    nf += 1\n",
        "\n",
        "# 이 파라미터는 멱평균 앙상블에 있어 중요한 수치임. 최적의 수치를 찾기 바랍니다.    \n",
        "p = 21\n",
        "\n",
        "if nf &gt;= 2:\n",
        "    pred = 0\n",
        "    for j in range(nf): pred = pred + slist.iloc[:,j+1]**p \n",
        "    pred = pred / nf    \n",
        "    pred = pred**(1/p)\n",
        "\n",
        "    submit = pd.DataFrame({'id': slist.id, '18~20_ride': pred})\n",
        "    t = pd.Timestamp.now()\n",
        "    fname = \"1+3.csv\"\n",
        "    submit.to_csv(fname, index=False)\n",
        "    \n",
        "    print(fname)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afjRS73HgoRV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 산술 평균(가중치)\n",
        "first = pd.read_csv('0+4.csv')\n",
        "second = pd.read_csv('1+3.csv')\n",
        "third = pd.read_csv('rf2=238.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBkBvXDzgoKB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target = '18~20_ride'\n",
        "\n",
        "w1, w2, w3 = 0.22, 0.30, 0.48"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJ11gaUYgoJe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "W = w1*first[target] + w2*second[target] + w3*third[target]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uw3MSElcgoI9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 최종 서브미션 파일 만들기\n",
        "sub = pd.read_csv('submission_sample.csv')\n",
        "sub[target] = W\n",
        "sub.to_csv('Final_submission.csv')\n",
        "\n",
        "print('finish .. !')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
